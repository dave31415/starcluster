####################################
## StarCluster Configuration File ##
####################################
[global]
DEFAULT_TEMPLATE=smallcluster
# enable experimental features for this release
#ENABLE_EXPERIMENTAL=True
# number of seconds to wait when polling instances (default: 30s)
#REFRESH_INTERVAL=15
# specify a web browser to launch when viewing spot history plots
#WEB_BROWSER=chromium
# split the config into multiple files
#INCLUDE=~/.starcluster/aws, ~/.starcluster/keys, ~/.starcluster/vols

#############################################
## AWS Credentials and Connection Settings ##
#############################################
[aws info]
AWS_ACCESS_KEY_ID = AKIAII6OQGOPBXPILCZA
AWS_SECRET_ACCESS_KEY = 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
AWS_USER_ID=  9751-3920-3755
# Uncomment to specify a different Amazon AWS region  (OPTIONAL)
# (defaults to us-east-1 if not specified)
# NOTE: AMIs have to be migrated!
#AWS_REGION_NAME = us-west-2
#AWS_REGION_HOST = ec2.us-west-2.amazonaws.com
# Uncomment these settings when creating an instance-store (S3) AMI (OPTIONAL)
EC2_CERT = /home/davej/east.pem
EC2_PRIVATE_KEY = /home/davej/east.pem
# Uncomment these settings to use a proxy host when connecting to AWS
#AWS_PROXY = your.proxyhost.com
#AWS_PROXY_PORT = 8080
#AWS_PROXY_USER = yourproxyuser
#AWS_PROXY_PASS = yourproxypass

###########################
## Defining EC2 Keypairs ##
###########################
[key east]
KEY_LOCATION=~/.starcluster/user_keys/east.pem

################################
## Defining Cluster Templates ##
################################

[cluster small]
KEYNAME = east
# number of ec2 instances to launch
CLUSTER_SIZE = 3
# create the following user on the cluster
CLUSTER_USER = sgeadmin
# optionally specify shell (defaults to bash)
# (options: tcsh, zsh, csh, bash, ksh)
CLUSTER_SHELL = bash
# Uncomment to prepent the cluster tag to the dns name of all nodes created
# using this cluster config.  ie: mycluster-master and mycluster-node001
# If you choose to enable this option, it's recommended that you enable it in
# the DEFAULT_TEMPLATE so all nodes will automatically have the prefix
# DNS_PREFIX = True
# AMI to use for cluster nodes. These AMIs are for the us-east-1 region.
# Use the 'listpublic' command to list StarCluster AMIs in other regions
# The base i386 StarCluster AMI is ami-9bf9c9f2
# The base x86_64 StarCluster AMI is ami-3393a45a
# The base HVM StarCluster AMI is ami-6b211202
NODE_IMAGE_ID = ami-6b211202

# instance type for all cluster nodes
# (options: m3.large, i2.8xlarge, c3.2xlarge, hs1.8xlarge, c1.xlarge, r3.4xlarge, g2.2xlarge, m1.small, c1.medium, m3.2xlarge, c3.8xlarge, m2.xlarge, r3.2xlarge, t1.micro, cr1.8xlarge, r3.8xlarge, cc1.4xlarge, m1.medium, r3.large, c3.xlarge, i2.xlarge, m3.medium, cc2.8xlarge, m1.large, cg1.4xlarge, i2.2xlarge, c3.large, i2.4xlarge, c3.4xlarge, r3.xlarge, m1.xlarge, hi1.4xlarge, m2.4xlarge, m2.2xlarge, m3.xlarge)
NODE_INSTANCE_TYPE = r3.xlarge
# Launch cluster in a VPC subnet (OPTIONAL)
#SUBNET_ID=subnet-99999999
# Uncomment to assign public IPs to cluster nodes (VPC-ONLY) (OPTIONAL)
# WARNING: Using public IPs with a VPC requires:
# 1. An internet gateway attached to the VPC
# 2. A route table entry linked to the VPC's internet gateway and associated
#    with the VPC subnet with a destination CIDR block of 0.0.0.0/0
# WARNING: Public IPs allow direct access to your VPC nodes from the internet
#PUBLIC_IPS=True
# Uncomment to disable installing/configuring a queueing system on the
# cluster (SGE)
#DISABLE_QUEUE=True
# Uncomment to specify a different instance type for the master node (OPTIONAL)
# (defaults to NODE_INSTANCE_TYPE if not specified)
#MASTER_INSTANCE_TYPE = m1.small
# Uncomment to specify a separate AMI to use for the master node. (OPTIONAL)
# (defaults to NODE_IMAGE_ID if not specified)
#MASTER_IMAGE_ID = ami-3393a45a (OPTIONAL)
# availability zone to launch the cluster in (OPTIONAL)
# (automatically determined based on volumes (if any) or
# selected by Amazon if not specified)
#AVAILABILITY_ZONE = us-west-2a
# list of volumes to attach to the master node (OPTIONAL)
# these volumes, if any, will be NFS shared to the worker nodes
# see "Configuring EBS Volumes" below on how to define volume sections

VOLUMES = bigdata,homedir

# list of plugins to load after StarCluster's default setup routines (OPTIONAL)
# see "Configuring StarCluster Plugins" below on how to define plugin sections

PLUGINS = pkginstaller,createusers,ipcluster,tmux,hadoop,xvfb,R,rstudio,shiny,spark

# list of permissions (or firewall rules) to apply to the cluster's security
# group (OPTIONAL).
#PERMISSIONS = ssh, http
# Uncomment to always create a spot cluster when creating a new cluster from
# this template. The following example will place a $0.50 bid for each spot
# request.

SPOT_BID = 0.07

# Uncomment to specify one or more userdata scripts to use when launching
# cluster instances. Supports cloudinit. All scripts combined must be less than
# 16KB
#USERDATA_SCRIPTS = /path/to/script1, /path/to/script2

###########################################
## Defining Additional Cluster Templates ##
###########################################

[cluster medium]
# Declares that this cluster uses smallcluster as defaults
EXTENDS=small
# This section is the same as smallcluster except for the following settings
NODE_INSTANCE_TYPE = r3.2xlarge
CLUSTER_SIZE=5

[cluster large]
# Declares that this cluster uses mediumcluster as defaults
EXTENDS=medium
CLUSTER_SIZE=10

#############################
## Configuring EBS Volumes ##
#############################

[volume bigdata]
VOLUME_ID = vol-cfb75d8a
MOUNT_PATH = /bigdata

[volume homedir]
VOLUME_ID = vol-2f89636a
MOUNT_PATH = /home

# By default StarCluster will attempt first to mount the entire volume device,
# failing that it will try the first partition. If you have more than one
# partition you will need to set the PARTITION number, e.g.:
# [volume oceandata]
# VOLUME_ID = vol-d7777777
# MOUNT_PATH = /mydata
# PARTITION = 2

############################################
## Configuring Security Group Permissions ##
############################################
# Sections starting with "permission" define security group rules to
# automatically apply to newly created clusters. IP_PROTOCOL in the following
# examples can be can be: tcp, udp, or icmp. CIDR_IP defaults to 0.0.0.0/0 or
# "open to the # world"

# open port 80 on the cluster to the world
# [permission http]
# IP_PROTOCOL = tcp
# FROM_PORT = 80
# TO_PORT = 80

# open https on the cluster to the world
# [permission https]
# IP_PROTOCOL = tcp
# FROM_PORT = 443
# TO_PORT = 443

# open port 80 on the cluster to an ip range using CIDR_IP
# [permission http]
# IP_PROTOCOL = tcp
# FROM_PORT = 80
# TO_PORT = 80
# CIDR_IP = 18.0.0.0/8

# restrict ssh access to a single ip address (<your_ip>)
# [permission ssh]
# IP_PROTOCOL = tcp
# FROM_PORT = 22
# TO_PORT = 22
# CIDR_IP = <your_ip>/32

#####################################
## Configuring StarCluster Plugins ##
#####################################
# [plugin myplugin]
# NOTE: myplugin module must either live in ~/.starcluster/plugins or be
# on your PYTHONPATH
# SETUP_CLASS = myplugin.SetupClass
# extra settings are passed as __init__ arguments to your plugin:
# SOME_PARAM_FOR_MY_PLUGIN = 1
# SOME_OTHER_PARAM = 2

######################                                                                  ## My Plugins ##                
######################  

[plugin R]
SETUP_CLASS = rstudio.RInstaller

[plugin rstudio]
SETUP_CLASS = rstudio.RStudioServerInstaller

[plugin shiny]
SETUP_CLASS = rstudio.ShinyServerInstaller

[plugin spark]
SETUP_CLASS = spark.SparkInstaller

[plugin fake]
SETUP_CLASS = fake.Fake

######################
## Built-in Plugins ##
######################
# See http://star.mit.edu/cluster/docs/latest/plugins for plugin details.
#

# Use this plugin to install one or more packages on all nodes
[plugin pkginstaller]
SETUP_CLASS = starcluster.plugins.pkginstaller.PackageInstaller
# # list of apt-get installable packages
PACKAGES = mongodb, python-pymongo, r-base-dev, postgresql-client

[plugin rstudio]
SETUP_CLASS = rstudio.RStudioServerInstaller

# Use this plugin to create one or more cluster users and download all user ssh
# keys to $HOME/.starcluster/user_keys/<cluster>-<region>.tar.gz
[plugin createusers]
SETUP_CLASS = starcluster.plugins.users.CreateUsers
#NUM_USERS = 30
# # you can also comment out NUM_USERS and specify exact usernames, e.g.
usernames = davej,jm,suman,aravind,debbie,ken,aaron,jspens,mmason,sean,anand,rstudio,shiny
DOWNLOAD_KEYS = True

#
# Use this plugin to configure the Condor queueing system
# [plugin condor]
# SETUP_CLASS = starcluster.plugins.condor.CondorPlugin
#
# The SGE plugin is enabled by default and not strictly required. Only use this
# if you want to tweak advanced settings in which case you should also set
# DISABLE_QUEUE=TRUE in your cluster template. See the plugin doc for more
# details.
# [plugin sge]
# SETUP_CLASS = starcluster.plugins.sge.SGEPlugin
# MASTER_IS_EXEC_HOST = False
#
# The IPCluster plugin configures a parallel IPython cluster with optional
# web notebook support. This allows you to run Python code in parallel with low
# latency message passing via ZeroMQ.
[plugin ipcluster]
SETUP_CLASS = starcluster.plugins.ipcluster.IPCluster
# # Enable the IPython notebook server (optional)
ENABLE_NOTEBOOK = True
# # Set a password for the notebook for increased security
# # This is optional but *highly* recommended
NOTEBOOK_PASSWD = beachworks
# # Set a custom directory for storing/loading notebooks (optional)
# NOTEBOOK_DIRECTORY = /path/to/notebook/dir
# # Set a custom packer. Must be one of 'json', 'pickle', or 'msgpack'
# # This is optional.
PACKER = pickle
#
# Use this plugin to create a cluster SSH "dashboard" using tmux. The plugin
# creates a tmux session on the master node that automatically connects to all
# the worker nodes over SSH. Attaching to the session shows a separate window
# for each node and each window is logged into the node via SSH.
[plugin tmux]
SETUP_CLASS = starcluster.plugins.tmux.TmuxControlCenter
#
# Use this plugin to change the default MPI implementation on the
# cluster from OpenMPI to MPICH2.
# [plugin mpich2]
# SETUP_CLASS = starcluster.plugins.mpich2.MPICH2Setup
#
# Configure a hadoop cluster. (includes dumbo setup)
[plugin hadoop]
SETUP_CLASS = starcluster.plugins.hadoop.Hadoop
#
# Configure a distributed MySQL Cluster
[plugin mysqlcluster]
SETUP_CLASS = starcluster.plugins.mysql.MysqlCluster
NUM_REPLICAS = 2
DATA_MEMORY = 200M
INDEX_MEMORY = 100M
DUMP_FILE = test.sql
DUMP_INTERVAL = 60
DEDICATED_QUERY = True
NUM_DATA_NODES = 3
#
# Install and setup an Xvfb server on each cluster node
[plugin xvfb]
SETUP_CLASS = starcluster.plugins.xvfb.XvfbSetup


